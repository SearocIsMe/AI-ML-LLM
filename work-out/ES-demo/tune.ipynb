{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from common.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from elasticsearch import Elasticsearch,helpers\n",
    "from elasticsearch.helpers import parallel_bulk\n",
    "from elasticsearch.helpers import streaming_bulk\n",
    "from es_pandas import es_pandas\n",
    "\n",
    "# 导入datetime库\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "import modin.pandas as mpd\n",
    "#import ray\n",
    "#ray.shutdown()\n",
    "#ray.init(num_cpus=4)\n",
    "\n",
    "#import commond.ipynb from same folder\n",
    "import import_ipynb\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-05 12:49:16,667\tINFO resource_spec.py:212 -- Starting Ray with 2.54 GiB memory available for workers and up to 1.27 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-07-05 12:49:16,973\tINFO services.py:1148 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.200',\n",
       " 'redis_address': '192.168.1.200:56932',\n",
       " 'object_store_address': '/tmp/ray/session_2020-07-05_12-49-16_664218_480/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-07-05_12-49-16_664218_480/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-07-05_12-49-16_664218_480'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import ray\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(num_cpus=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Worker(object):\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    def train(self):\n",
    "        self.logger.warning(\"print from inside worker\")\n",
    "    def log_time(self, msg):\n",
    "        # datetime object containing current date and time\n",
    "        now = datetime.datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "        self.logger.info(msg)\n",
    "        self.logger.info(dt_string)\n",
    "    def get_interests_columns_local(self):\n",
    "        cols = [\n",
    "            'Weight',\n",
    "            'Frequency',\n",
    "            'Spreader_20FT',\n",
    "            'Spreader_40FT',\n",
    "            'Spreader_45FT',\n",
    "            'Spreader_Twin',\n",
    "            'OT_Control STS_Hoist Up (Controller)',\n",
    "            'OT_Control STS_Hoist Down (Controller)',\n",
    "            'OT_Control STS_Trolley Forward (Controller)',\n",
    "            'OT_Control STS_Trolley Reverse (Controller)',\n",
    "            'Phase A Current',\n",
    "            'Phase B Current',\n",
    "            'Phase C Current',\n",
    "            'Average Current',\n",
    "            'Neutral Current',\n",
    "            'Voltage Vab',\n",
    "            'Voltage Vbc',\n",
    "            'Voltage Vca',\n",
    "            '3 Phase Real Power',\n",
    "            '3 Phase Reactive Power',\n",
    "            '3 Phase Apparent Power',\n",
    "            '3 Phase Positive Real Energy Used',\n",
    "            '3 Phase Negative Real Energy Used',\n",
    "            '3 Phase Positive Reactive Energy Used',\n",
    "            '3 Phase Negative Reactive Energy Used',\n",
    "            '3 Phase Apparent Energy',\n",
    "            'OT_Control STS_Gantry Right (Controller)',\n",
    "            'OT_Control STS_Gantry Left (Controller)',\n",
    "            'OT_Control STS_Boom Up (Controller)',\n",
    "            'OT_Control STS_Boom Down (Controller)',\n",
    "            'Trolley Position',\n",
    "            'Load Cell1 Data',\n",
    "            'Load Cell2 Data',\n",
    "            'Load Cell3 Data',\n",
    "            'Load Cell4 Data',\n",
    "            'SP STS_Landed']\n",
    "        return cols        \n",
    "    def ingest_bulk_dataframe_modin(self, start_date, end_date, crane_number):\n",
    "        self.logger.info(\"start the ingest_bulk_dataframe_modin \")\n",
    "        # 获取时间间隔\n",
    "        delta = end_date - start_date\n",
    "\n",
    "        ds = pd.DataFrame()\n",
    "        const_ds = pd.DataFrame()\n",
    "\n",
    "        const_ds.at[0, \"CraneNumber\"] = crane_number\n",
    "        const_ds.at[1, \"CraneNumber\"] = crane_number\n",
    "        const_ds.at[0, \"Twistlock\"] = 0\n",
    "        const_ds.at[1, \"Twistlock\"] = 1\n",
    "        const_ds.at[0, \"Comm Status\"] = 'OK'\n",
    "        const_ds.at[1, \"Comm Status\"] = 'False'\n",
    "        const_ds.at[0, \"Asset Type\"] = 'QC'\n",
    "        const_ds.at[1, \"Asset Type\"] = 'YC'\n",
    "\n",
    "        col_list = self.get_interests_columns_local.remote()\n",
    "\n",
    "        return\n",
    "        \"\"\"\n",
    "        # 遍历获得每一个时间点\n",
    "        for i in range(int(delta.total_seconds())+1):\n",
    "            #print_time(\"randint\")\n",
    "            ss = random.randint(10, 100)\n",
    "            temp = start_date + datetime.timedelta(seconds=i)\n",
    "            dt1 = temp + datetime.timedelta(milliseconds=ss)\n",
    "            dt2 = dt1 + datetime.timedelta(milliseconds=500)\n",
    "\n",
    "            #print_time(\"start create df \")\n",
    "            df = pd.DataFrame(np.random.randint(10,1000,size=(2, 36)), columns=list(col_list))\n",
    "            #print_time(\"finish create df \")\n",
    "\n",
    "            df.at[0, \"timestamp\"] = dt1.strftime(\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "            df.at[1, \"timestamp\"] = dt2.strftime(\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "\n",
    "            #print_time(\"finish add df \")\n",
    "            new_df = pd.concat([df, const_ds], axis=1)\n",
    "\n",
    "            #print_time(\"finish cancat df \")\n",
    "            ds = pd.concat([ds, new_df], axis=0)\n",
    "            #print_time(\"finish append df \")\n",
    "            del new_df\n",
    "            #print_time(\"finish delete new_df \")\n",
    "            del df\n",
    "\n",
    "            if ds.shape[0] >= 14400:\n",
    "               #print_time(\"start ingestion to ES \")\n",
    "               log_time.remote(\"finish ingestion to ES \")\n",
    "               msg = dt2.strftime(\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "               print('Ingest %s  is completed!' % msg)\n",
    "               ds = ds[0:0]\n",
    "\n",
    "        if ds.shape[0] > 0:\n",
    "           ds = ds[0:0] \n",
    "        return \"done!\"\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectID(8603ac10b8c093b315c675b2010000c801000000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-05 12:52:58,911\tERROR worker.py:1012 -- Possible unhandled error from worker: \u001b[36mray::Worker.ingest_bulk_dataframe_modin()\u001b[39m (pid=1115, ip=192.168.1.200)\n",
      "  File \"python/ray/_raylet.pyx\", line 452, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 407, in ray._raylet.execute_task.function_executor\n",
      "  File \"<ipython-input-5-5d8a646a6673>\", line 70, in ingest_bulk_dataframe_modin\n",
      "AttributeError: 'function' object has no attribute 'remote'\n"
     ]
    }
   ],
   "source": [
    "worker = Worker.remote()\n",
    "\n",
    "crane = 'PQC' + str(random.randint(500, 900))\n",
    "# 创建开始时间点和结束时间点\n",
    "dt_start = datetime.datetime(2017,1,1,0,0,1)\n",
    "dt_end =   datetime.datetime(2017,1,2,0,0,0)\n",
    "worker.ingest_bulk_dataframe_modin.remote(dt_start, dt_end, crane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return dataframe by timerange\n",
    "def ingest_bulk_dataframe(start_date, end_date, crane_number):\n",
    "    # 获取时间间隔\n",
    "    delta = end_date - start_date\n",
    "    \n",
    "    ds = pd.DataFrame()\n",
    "    const_ds = pd.DataFrame()\n",
    "\n",
    "    const_ds.at[0, \"CraneNumber\"] = crane_number\n",
    "    const_ds.at[1, \"CraneNumber\"] = crane_number\n",
    "    const_ds.at[0, \"Twistlock\"] = 0\n",
    "    const_ds.at[1, \"Twistlock\"] = 1\n",
    "    const_ds.at[0, \"Comm Status\"] = 'OK'\n",
    "    const_ds.at[1, \"Comm Status\"] = 'False'\n",
    "    const_ds.at[0, \"Asset Type\"] = 'QC'\n",
    "    const_ds.at[1, \"Asset Type\"] = 'YC'\n",
    "    \n",
    "    col_list = get_interests_columns_simple()\n",
    "    # 遍历获得每一个时间点\n",
    "    for i in range(int(delta.total_seconds())+1):\n",
    "        #print_time(\"randint\")\n",
    "        ss = 125 #random.randint(10, 100)\n",
    "        temp = start_date + datetime.timedelta(seconds=i)\n",
    "        dt1 = temp + datetime.timedelta(milliseconds=ss)\n",
    "        dt2 = dt1 + datetime.timedelta(milliseconds=500)\n",
    "        \n",
    "        #print_time(\"start create df \")\n",
    "        df = pd.DataFrame(np.random.randint(10,1000,size=(2, len(col_list))), columns=list(col_list))\n",
    "        #print_time(\"finish create df \")\n",
    "        \n",
    "        df.at[0, \"timestamp\"] = dt1.strftime(\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "        df.at[1, \"timestamp\"] = dt2.strftime(\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "\n",
    "        #print_time(\"finish add df \")\n",
    "        new_df = pd.concat([df, const_ds], axis=1)\n",
    "        del df\n",
    "        #print_time(\"finish cancat df \")\n",
    "        ds = pd.concat([ds, new_df], axis=0)\n",
    "        #ds = ds.append(new_df)\n",
    "        #print(ds)\n",
    "        #print_time(\"finish append df \")\n",
    "\n",
    "        if ds.shape[0] >= 14400:\n",
    "           #print_time(\"start ingestion to ES \")\n",
    "           print_time(\"finish ingestion to ES \")\n",
    "           msg = dt2.strftime(\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "           print('Ingest %s  is completed!' % msg)\n",
    "           ds = ds[0:0]\n",
    "           \n",
    "    if ds.shape[0] > 0:\n",
    "       ds = ds[0:0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_time(msg):\n",
    "    # datetime object containing current date and time\n",
    "    now = datetime.datetime.now()\n",
    "    # dd/mm/YY H:M:S\n",
    "    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "    print(msg, dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "crane = 'PQC' + str(random.randint(500, 900))\n",
    "# 创建开始时间点和结束时间点\n",
    "dt_start = datetime.datetime(2017,1,1,0,0,1)\n",
    "dt_end =   datetime.datetime(2017,1,2,0,0,0)\n",
    "ray.get(ingest_bulk_dataframe_modin.remote(dt_start, dt_end, crane))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def f(x):\n",
    "    return x * x\n",
    "\n",
    "futures = [f.remote(i) for i in range(4)]\n",
    "print(ray.get(futures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-05T20:11:10.645868+0800\n",
      "2020-07-05T20:11:10.645868+08:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.astimezone().strftime(\"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "print(dt_string)\n",
    "print(now.astimezone().isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crane = 'PQC' + str(random.randint(500, 900))\n",
    "# 创建开始时间点和结束时间点\n",
    "dt_start = datetime.datetime(2017,1,1,0,0,1)\n",
    "dt_end =   datetime.datetime(2017,1,2,0,0,0)\n",
    "ingest_bulk_dataframe_modin(dt_start, dt_end, crane)\n",
    "print('Ingest %s  is completed!' % crane)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
