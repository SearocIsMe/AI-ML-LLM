{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import re\n",
    "import asyncio\n",
    "import logging\n",
    "from collections import deque\n",
    "\n",
    "import ujson as json\n",
    "#import commond.ipynb from same folder\n",
    "import import_ipynb\n",
    "from common import *\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\n",
    "    fmt='%(asctime)s [%(levelname)s] %(name)s: %(message)s',\n",
    ")\n",
    "handler.setFormatter(formatter)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_create_index_dsl(shrads=1):\n",
    "    request_body = {\n",
    "        \"settings\": {\n",
    "            \"index.mapping.ignore_malformed\": True,\n",
    "            \"number_of_shards\": shrads,\n",
    "            \"number_of_replicas\": 1,\n",
    "            \"analysis\": {\n",
    "                \"analyzer\": {\n",
    "                    \"name_analyzer\": {\n",
    "                        \"tokenizer\": \"name_index\"\n",
    "                    },\n",
    "                    \"address_analyzer\": {\n",
    "                        \"tokenizer\": \"address_index\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"shop\": {\n",
    "                \"_all\": {\n",
    "                    \"enabled\": False\n",
    "                },\n",
    "                \"dynamic\": \"false\",\n",
    "                \"properties\": {\n",
    "                    \"sid\": {\n",
    "                        \"type\": \"keyword\"\n",
    "                    },\n",
    "                    \"name\": {\n",
    "                        \"type\": \"text\",\n",
    "                        \"analyzer\": \"name_analyzer\",\n",
    "                        \"search_analyzer\": \"name_analyzer\"\n",
    "                    },\n",
    "                    \"address\": {\n",
    "                        \"type\": \"text\",\n",
    "                        \"analyzer\": \"address_analyzer\",\n",
    "                        \"search_analyzer\": \"address_analyzer\"\n",
    "                    },\n",
    "                    \"tels\": {\n",
    "                        \"type\": \"keyword\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return request_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_index(es, index_name):\n",
    "    res = es.indices.delete(index=index_name)\n",
    "    print(\"delete res: \", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(es, index_name, shards):\n",
    "    if es.indices.exists(index_name):\n",
    "        print(f\"{index_name} exists\")\n",
    "        return True\n",
    "    request_body = get_create_index_dsl(shards)\n",
    "    res = es.indices.create(index=index_name, body=request_body)\n",
    "    print('done')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_create_index():\n",
    "    es_hosts = None\n",
    "    es_hosts = ['localhost']\n",
    "    indexs = ['lifestyle', 'yellowpage', 'bkwd']\n",
    "    es = Elasticsearch(es_hosts, port=9200)\n",
    "    for ix in indexs:\n",
    "        create_index(es, ix, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingrest_bulk_json(json_file, index_name):\n",
    "    try:\n",
    "        # make the bulk call, and get a response\n",
    "        results = list(parallel_bulk(client=es, actions=json_file, index=\"index_name\",chunk_size=1000, thread_count=4, queue_size=16))\n",
    "        elf.assertTrue(len(set([r[1] for r in results])) > 1)\n",
    "        print (\"\\nRESPONSE:\", results)\n",
    "    except Exception as e:\n",
    "        print(\"\\nERROR:\", e)\n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest bulk from json file, which is generated from filename.\n",
    "json_file = 'sample.json'\n",
    "\n",
    "ingrest_bulk_json(json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
