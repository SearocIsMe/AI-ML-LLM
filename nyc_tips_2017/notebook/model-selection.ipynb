{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We will evaluate a diverse set of nonlinear and ensemble machine learning algorithms, specifically:\n",
    "\n",
    "Nonlinear Algorithms:\n",
    "\n",
    "k-Nearest Neighbors\n",
    "Classification and Regression Tree\n",
    "Support Vector Machine\n",
    "Naive Bayes\n",
    "Ensemble Algorithms:\n",
    "\n",
    "Bagged Decision Trees\n",
    "Random Forest\n",
    "Extra Trees\n",
    "Gradient Boosting Machine\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spot check on engineered-features\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn import preprocessing\n",
    "from tpot import TPOTRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a dict of standard models to evaluate {name:object}\n",
    "def define_models(models=dict()):\n",
    "    # nonlinear models\n",
    "    models['knn'] = KNeighborsClassifier(n_neighbors=7)\n",
    "    models['cart'] = DecisionTreeClassifier()\n",
    "    models['svm'] = SVC()\n",
    "    models['bayes'] = GaussianNB()\n",
    "    # ensemble models\n",
    "    models['bag'] = BaggingClassifier(n_estimators=100)\n",
    "    models['rf'] = RandomForestClassifier(n_estimators=100)\n",
    "    models['et'] = ExtraTreesClassifier(n_estimators=100)\n",
    "    models['gbm'] = GradientBoostingClassifier(n_estimators=100)\n",
    "    models['xgb'] = XGBClassifier(n_estimators=100)\n",
    "    print('Defined %d models' % len(models))\n",
    "    return models\n",
    " \n",
    "# evaluate a single model\n",
    "def evaluate_model(trainX, trainy, testX, testy, model):\n",
    "    # fit the model\n",
    "    model.fit(trainX, trainy)\n",
    "    # make predictions\n",
    "    yhat = model.predict(testX)\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(testy, yhat)\n",
    "    return accuracy * 100.0\n",
    " \n",
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(trainX, trainy, testX, testy, models):\n",
    "    results = dict()\n",
    "    for name, model in models.items():\n",
    "        # evaluate the model\n",
    "        results[name] = evaluate_model(trainX, trainy, testX, testy, model)\n",
    "        # show process\n",
    "        print('>%s: %.3f' % (name, results[name]))\n",
    "    return results\n",
    " \n",
    "# print and plot the results\n",
    "def summarize_results(results, maximize=True):\n",
    "    # create a list of (name, mean(scores)) tuples\n",
    "    mean_scores = [(k,v) for k,v in results.items()]\n",
    "    # sort tuples by mean score\n",
    "    mean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "    # reverse for descending order (e.g. for accuracy)\n",
    "    if maximize:\n",
    "        mean_scores = list(reversed(mean_scores))\n",
    "    print()\n",
    "    for name, score in mean_scores:\n",
    "        print('Name=%s, Score=%.3f' % (name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID  RatecodeID  PULocationID  DOLocationID  passenger_count  \\\n",
      "0         2           1            40           141              1.0   \n",
      "1         2           1            74            74              1.0   \n",
      "2         2           1            65           143              2.0   \n",
      "3         2           1           165            40              1.0   \n",
      "4         2           1            94           120              1.0   \n",
      "\n",
      "   trip_distance  fare_amount  extra  tolls_amount  total_amount  \\\n",
      "0           2.91         13.0    0.0           0.0         16.56   \n",
      "1           0.36          3.5    0.0           0.0          4.30   \n",
      "2           2.31         12.5    0.0           0.0         15.96   \n",
      "3           0.96          6.5    1.0           0.0          9.96   \n",
      "4           2.86         15.0    0.0           0.0         18.96   \n",
      "\n",
      "   payment_type  duration  day_of_week      speed  tip_amount  \n",
      "0             1    1194.0            5   8.773869        2.76  \n",
      "1             2     113.0            5  11.469027        0.00  \n",
      "2             1     886.0            2   9.386005        2.66  \n",
      "3             1     392.0            2   8.816327        1.66  \n",
      "4             1    1243.0            0   8.283186        3.16  \n"
     ]
    }
   ],
   "source": [
    "def clean_data(df):\n",
    "    df_ = df.copy()\n",
    "    # remove the 2016-01-23 data since its too less comapre others days,\n",
    "    # maybe quality is not good\n",
    "    # df_ = df_[(df_.pickup_date != '2016-01-23') & (df_.dropoff_date != '2016-01-23')]\n",
    "    # potential passenger_count outlier\n",
    "    df_ = df_[(df_['passenger_count'] <= 6) & (df_['passenger_count'] > 0)]\n",
    "    return df_\n",
    "\n",
    "### ================================================ ###\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    df_train = pd.read_csv('../data/train.csv')\n",
    "    df_test = pd.read_csv('../data/test.csv')\n",
    "    # sample train data for fast job\n",
    "    # df_train = df_train.sample(n=100)\n",
    "    # clean train data\n",
    "    df_train_ = clean_data(df_train)\n",
    "    # merge train and test data for fast process and let model view test data when training as well\n",
    "    df_all = pd.concat([df_train_, df_test], axis=0)\n",
    "    return df_all, df_train_, df_test\n",
    "\n",
    "df_all_, df_train, df_test = load_data()\n",
    "\n",
    "features = ['VendorID',\n",
    "            'RatecodeID',\n",
    "            'PULocationID',\n",
    "            'DOLocationID',\n",
    "            'passenger_count',\n",
    "            'trip_distance',\n",
    "            'fare_amount',\n",
    "            'extra',\n",
    "            'tolls_amount',\n",
    "            'total_amount',\n",
    "            'payment_type',\n",
    "            'duration',\n",
    "            'day_of_week',\n",
    "            'speed',\n",
    "            'tip_amount']\n",
    "      \n",
    "X_train = df_all_[features].values\n",
    "y_train = X_train[:, X_train.shape[1]-1]\n",
    "\n",
    "X_test = df_test[features].values\n",
    "y_test = X_test[:, X_test.shape[1]-1]\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "print (df_all_[features].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5000\n",
    "\n",
    "X_train = X_train[:sample_size]\n",
    "y_train = y_train[:sample_size]\n",
    "\n",
    "X_test = X_test[:sample_size]\n",
    "y_test = y_test[:sample_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of y_train: multiclass\n",
      "type of y_test: multiclass\n"
     ]
    }
   ],
   "source": [
    "print('type of y_train: %s' % type_of_target(y_train))\n",
    "print('type of y_test: %s' % type_of_target(y_test))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 9 models\n",
      ">knn: 57.900\n",
      ">svm: 59.060\n",
      ">gbm: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/searoc/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">xgb: 59.720\n",
      ">cart: 59.960\n",
      ">bag: 60.000\n",
      ">rf: 59.480\n",
      ">bayes: 52.660\n",
      ">et: 59.420\n",
      "()\n",
      "Name=bag, Score=60.000\n",
      "Name=cart, Score=59.960\n",
      "Name=xgb, Score=59.720\n",
      "Name=rf, Score=59.480\n",
      "Name=et, Score=59.420\n",
      "Name=svm, Score=59.060\n",
      "Name=knn, Score=57.900\n",
      "Name=bayes, Score=52.660\n",
      "Name=gbm, Score=0.000\n"
     ]
    }
   ],
   "source": [
    "# get model list\n",
    "models = define_models()\n",
    "# evaluate models\n",
    "results = evaluate_models(X_train, y_train, X_test, y_test, models)\n",
    "# summarize results\n",
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
