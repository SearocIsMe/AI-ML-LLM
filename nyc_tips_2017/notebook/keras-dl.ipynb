{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from common.ipynb\n"
     ]
    }
   ],
   "source": [
    "# python 3\n",
    "# -*- coding: utf-8 -*-\n",
    "# load basics library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tpot import TPOTRegressor\n",
    "# DL\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers, callbacks, optimizers\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import commond.ipynb from same folder\n",
    "import import_ipynb\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
      "0         2  2017-01-07 12:47:25   2017-01-07 13:07:19                  N   \n",
      "1         2  2017-01-21 12:21:04   2017-01-21 12:22:57                  N   \n",
      "\n",
      "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
      "0           1            40           141              1.0           2.91   \n",
      "1           1            74            74              1.0           0.36   \n",
      "\n",
      "   fare_amount ...   ehail_fee  improvement_surcharge  total_amount  \\\n",
      "0         13.0 ...         NaN                    0.3         16.56   \n",
      "1          3.5 ...         NaN                    0.3          4.30   \n",
      "\n",
      "   payment_type  trip_type  duration  day_of_week  weekend      speed  tip  \n",
      "0             1        1.0    1194.0            5        1   8.773869    1  \n",
      "1             2        1.0     113.0            5        1  11.469027    0  \n",
      "\n",
      "[2 rows x 24 columns]\n",
      "trainX shape:  (2086637, 15)\n",
      "trainy shape:  (2086637,)\n",
      "testX  shape:  (1019792, 15)\n",
      "testy  shape:  (1019792,)\n",
      "trainX shape:  (2086637, 15)\n",
      "trainy shape:  (2086637,)\n",
      "testX  shape:  (1019792, 15)\n",
      "testy  shape:  (1019792,)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, testX, testy = load_dataSet()\n",
    "print(\"trainX shape: \", trainX.shape)\n",
    "print(\"trainy shape: \", trainy.shape)\n",
    "print(\"testX  shape: \", testX.shape)\n",
    "print(\"testy  shape: \", testy.shape)\n",
    "trainX, scaler_trainX = preprocess_data(trainX.values)\n",
    "trainy = trainy.values\n",
    "testX, scaler_testX = preprocess_data(testX.values)\n",
    "testy = testy.values\n",
    "\n",
    "\n",
    "print(\"trainX shape: \", trainX.shape)\n",
    "print(\"trainy shape: \", trainy.shape)\n",
    "print(\"testX  shape: \", testX.shape)\n",
    "print(\"testy  shape: \", testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim=trainX.shape[1], kernel_initializer='glorot_uniform', activation='relu'))\n",
    "model.add(Dropout(0.71))\n",
    "model.add(Dense(512, kernel_initializer='glorot_uniform', activation='relu'))\n",
    "model.add(Dropout(0.60))\n",
    "model.add(Dense(256, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dropout(0.40))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile model\n",
    "#model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.02, momentum=0.9), metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              16384     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 672,769\n",
      "Trainable params: 672,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1877973 samples, validate on 208664 samples\n",
      "Epoch 1/100\n",
      "1877973/1877973 [==============================] - 150s 80us/step - loss: 0.3621 - acc: 0.6322 - val_loss: 0.1133 - val_acc: 0.6488\n",
      "Epoch 2/100\n",
      "1877973/1877973 [==============================] - 140s 74us/step - loss: 0.3629 - acc: 0.6354 - val_loss: 0.1688 - val_acc: 0.6496\n",
      "Epoch 00002: early stopping\n",
      "======================================================================\n",
      "TRAIN RESULT : \n",
      "{'val_loss': [0.11325288093486031, 0.16877075914711004], 'val_acc': [0.6487702718268452, 0.6496089406916231], 'loss': [0.3621398318490818, 0.36290341976388557], 'acc': [0.6321794828789318, 0.6353978465081643]}\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# simple early stopping, With GPU enabled\n",
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1)\n",
    "\n",
    "XTraining, XValidation, YTraining, YValidation = train_test_split(trainX, trainy, test_size=0.1, shuffle= True) # before model building\n",
    "\n",
    "#Use a Manual Verification Dataset\n",
    "history = model.fit(XTraining, YTraining, validation_data=(XValidation, YValidation),\n",
    "                    epochs=100, batch_size=32, shuffle=True, callbacks=[es])\n",
    "\n",
    "print ('='*70)\n",
    "print ('TRAIN RESULT : ')\n",
    "print (history.history)\n",
    "print ('='*70)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "＃#　Below is not using GPU\n",
    "![noGPU.png](picture/noGPU.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
